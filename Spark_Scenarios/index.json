{
  "title": "Create Spark Application on BlueData App Workbench",
  "description": "Process to build Spark App with BlueData Workbench on EPIC platform.",
  "difficulty": "intermediate",
  "time": "30 minutes",
  "details": {
    "steps": [
    { "title": "Step 1 - Preparing the Environment","text": "step1.md"},
    { "title": "Step 2 - Getting Started.", "text": "step2.md"},
    { "title": "Step 3 - Creating the Dockerfile.", "text": "step3.md"},
	{ "title": "Step 4 - Creating sub directory under appconfig.", "text": "step4.md"},
	{ "title": "Step 5 - Creating spark, hadoop and java configuration files.", "text": "step5.md"},
	{ "title": "Step 6 - Building the Bin File using BlueData App Workbench.", "text": "step6.md"},
	{ "title": "Step 7 - Finalising the build for Spark.", "text": "step7.md"}
    ],
    "intro": {
      "text": "intro.md",
      "code": "init.sh"
    },
    "finish": {
      "text": "finish.md"
    },
    "assets": {
       "host01": [
                 {"file": "Dockerfile", "target": "/root/test"},
                 {"file": "hadoop", "target": "/root/test",  "chmod": "+x" }, 
                 {"file": "core-site.xml", "target": "/root/test" },
                 {"file": "spark-env.sh", "target": "/root/test",  "chmod": "+x" },    
                 {"file": "spark-slave", "target": "/root/test",  "chmod": "+x" },
                 {"file": "total_vcores.sh", "target": "/root/test",  "chmod": "+x" },
                 {"file": "spark-defaults.conf", "target": "/root/test" }, 
                 {"file": "spark-master","target": "/root/test",  "chmod": "+x" },
                 {"file": "Logo_Spark.png", "target": "/root/test" },
				 {"file": "configure_java8.sh", "target": "/root/test" },
				 {"file": "appjob", "target": "/root/test" }
                ] 
    }
  },
  "environment": {
    "uilayout": "terminal",
    "uimessage1": "\u001b[32mInitializing BlueData Application Workbench environment.\u001b[m\r\n"
  },
  "backend": {
    "imageid": "centos-vm"
  }
}
